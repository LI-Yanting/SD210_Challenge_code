{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By - LI Yanting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Critere de performance\n",
    "def compute_pred_score(y_true, y_pred):\n",
    "    y_pred_unq =  np.unique(y_pred)\n",
    "    for i in y_pred_unq:\n",
    "        if((i != -1) & (i!= 1) & (i!= 0) ):\n",
    "            raise ValueError('The predictions can contain only -1, 1, or 0!')\n",
    "    y_comp = y_true * y_pred\n",
    "    score = float(10*np.sum(y_comp == -1) + np.sum(y_comp == 0))\n",
    "    score /= y_comp.shape[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_fname = 'training_templates.csv'\n",
    "y_train_fname = 'training_labels.txt'\n",
    "X_test_fname  = 'testing_templates.csv'\n",
    "y_train = np.loadtxt(y_train_fname, dtype=np.int)\n",
    "X_train = pd.read_csv(X_train_fname, sep=',', header=None).values\n",
    "X_test  = pd.read_csv(X_test_fname,  sep=',', header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is necessary to build a good training set. In general, this step should include sample selection and feature selection. In sample selection, some outlier data should be removed from the training set; In feature selection, some \"bad\" features should not be considered in order to dicrease the dim of the data. If the model gives all features the same importance, it will lead to over-fitting, the generalization ability of unknown data will be poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Processing Samples with KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is to select the training samples more likely to test set:\n",
    "For each sample in the test dataset, we select 50 nearest samples from the original training set to generate a new training set. (After an 'unique' operation, this new training set contains about 90000 samples.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
      "         metric_params=None, n_jobs=1, n_neighbors=30, p=2, radius=1.0)\n",
      "X_train_unique Shape:  (73596, 128)\n",
      "y_train_unique Shape:  (73596,)\n"
     ]
    }
   ],
   "source": [
    "# Sample Selection: KNN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=50, algorithm='ball_tree').fit(X_train_std)\n",
    "distances, indices = nbrs.kneighbors(X_test_std)\n",
    "new_indices = np.ravel(indices)\n",
    "uni_indices = np.unique(indices)\n",
    "print nbrs\n",
    "X_train_unique = X_train_std[uni_indices]\n",
    "y_train_unique = y_train[uni_indices]\n",
    "print \"X_train_unique Shape: \", X_train_unique.shape\n",
    "print \"y_train_unique Shape: \", y_train_unique.shape\n",
    "# Save new train set: X_train_unique and y_trian_unique\n",
    "np.savetxt(\"X_train_unique_50.csv\", X_train_unique, fmt='%.6e', delimiter=',')\n",
    "np.savetxt(\"y_train_unique_50.txt\", y_train_unique, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 Processing Features with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step should contain two parts: \n",
    "- select \"good\" features\n",
    "- PCA\n",
    "\n",
    "For feature selection, sklearn.SelectKBest and xgboost.plot_importance have been tried, but unfortunately, in SelectKBest, after trying all three types of function(chi2, mutual_info_classif and f_classif), there isn't a better result; there also remains some problems with xgboost.plot_importance to solve. Therefore, this part remains a feature selection to be completed.\n",
    "\n",
    "For the parameters in PCA, the purpose of whitening is to keep several eigenvalues of the output independent of each other. Svd_sover 'auto' could choose automaticly a solver most suitable for current situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=128, whiten=True, svd_solver='auto')\n",
    "X_train_pca = pca.fit_transform(X_train_unique)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a model and getting a evaluation of the model, the training set is splitted into X_train_split and X_test_split with a test_size of 0.2. For a large training set, this test_size could be smaller as 0.05 or even less, but in order to ensure enough test data to evaluate the model, here 20% of the data is chosen to be test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70218, 128) (70218,)\n",
      "(17555, 128) (17555,)\n",
      "0.0793528724828\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "seed = 0\n",
    "test_size = 0.2\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train_pca, y_train_unique, \n",
    "                                                                test_size=test_size, random_state=seed)\n",
    "print X_train_split.shape, y_train_split.shape\n",
    "print X_test_split.shape, y_test_split.shape\n",
    "print np.mean(y_train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to judge when it should return 0 as an uncertainty. The parameter threshold means the difference between the classification result with a higher probability and the one with a lower probability. In next step, a best threshold is searched from 0 to 0.99 to ensure that the general score to be almost the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(y_predict_proba, threshold=0.54):\n",
    "    y_predict = np.zeros((len(y_predict_proba)), dtype=np.int)\n",
    "    y_diff = np.add(y_predict_proba[:,1], -y_predict_proba[:,0])\n",
    "    y_predict = np.piecewise(y_diff,[y_diff<(-threshold),y_diff>threshold],[-1,1]).astype(int)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 Bagging with MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying single MLP, SVC, xgboost classifier, Random Forest and Bagging with MLP, the last model is chosen according to their testing score. An obstacle here is the tune of xgboost. In theory, xgboost should give a good performance but it takes too much time to tune and here remains some work to explore.\n",
    "\n",
    "For Bagging with MLP, it is difficult to find a relationship between the hidden_layer_sizes and the performance, but 2 layer is enough. n_estimators could be relatively large as 40 to give a more 'correct' result of classification. Max_samples and max_features could be relatively small to avoid over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Time:  1.754916\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "n_estimators = 40\n",
    "bagging = BaggingClassifier(base_estimator=MLPClassifier(solver='lbfgs', alpha=1e-4, \n",
    "                                                         hidden_layer_sizes=(200,200), random_state=27),\n",
    "                           n_estimators=n_estimators, max_samples=0.62, max_features=0.62, n_jobs=-1)\n",
    "bagging.fit(X_train_split, y_train_split)\n",
    "y_inter = bagging.predict_proba(X_test_split)\n",
    "end = time.clock()\n",
    "print \"Running Time: \",end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQf8f8IdFgVctfKcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12011e6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur le train : 0.102363998861\n"
     ]
    }
   ],
   "source": [
    "# To select a best Threshold:\n",
    "score_min = 1\n",
    "threshold = 0.7\n",
    "score = np.zeros(100)\n",
    "i=0\n",
    "plt.figure()\n",
    "for x in np.linspace(0, 0.99, num=100):\n",
    "    y_pred_train = predict(y_inter,x)\n",
    "    score[i] = compute_pred_score(y_test_split, y_pred_train)\n",
    "    if score[i] < score_min:\n",
    "        score_min = score[i]\n",
    "        threshold = x\n",
    "#     print('Threshold %s \\t Score : %s' %(x,score[i]))\n",
    "    i=i+1\n",
    "plt.plot(np.linspace(0, 0.99, num=100),score)\n",
    "plt.title('Score with threshold')\n",
    "plt.show()\n",
    "\n",
    "# Play with the best threshold\n",
    "y_pred_train = predict(y_inter,threshold)\n",
    "score = compute_pred_score(y_test_split, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 Play with the 'real data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training a model, here we use all the selected samples in the training set to train a new model for predicting. And then predict the X_test after this test set being processed with the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Time:  1.90521\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "n_estimators = 40\n",
    "bagging = BaggingClassifier(base_estimator=MLPClassifier(solver='lbfgs', alpha=1e-4, \n",
    "                                                         hidden_layer_sizes=(200,200), random_state=27),\n",
    "                           n_estimators=n_estimators, max_samples=0.62, max_features=0.62, n_jobs=-1)\n",
    "bagging.fit(X_train_pca, y_train_unique)\n",
    "y_inter = bagging.predict_proba(X_test_pca)\n",
    "\n",
    "# Play with the best threshold\n",
    "y_pred = predict(y_inter,0.45)\n",
    "np.savetxt('y_pred_bagging.txt', y_pred, fmt='%d')\n",
    "end = time.clock()\n",
    "print \"Running Time: \",end-start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
